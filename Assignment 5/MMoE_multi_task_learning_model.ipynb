{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMoE multi task learning model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLoLDSvXDK/It+OHCXfhhX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tripuragorla/CMPE-297-Assignments/blob/main/Assignment%205/MMoE_multi_task_learning_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De0DOkHAZ76W"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import activations, initializers, regularizers, constraints\n",
        "from tensorflow.keras.layers import Layer, InputSpec, Input, Dense\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import VarianceScaling\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VrZJa2aaBG7",
        "outputId": "b65ec3d0-f11e-4402-8019-0ceaddea3514"
      },
      "source": [
        "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.data.gz\n",
        "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.test.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-09 20:33:43--  http://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.data.gz\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6524338 (6.2M) [application/x-httpd-php]\n",
            "Saving to: ‘census-income.data.gz’\n",
            "\n",
            "census-income.data. 100%[===================>]   6.22M  2.86MB/s    in 2.2s    \n",
            "\n",
            "2021-11-09 20:33:45 (2.86 MB/s) - ‘census-income.data.gz’ saved [6524338/6524338]\n",
            "\n",
            "--2021-11-09 20:33:45--  http://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.test.gz\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3261416 (3.1M) [application/x-httpd-php]\n",
            "Saving to: ‘census-income.test.gz’\n",
            "\n",
            "census-income.test. 100%[===================>]   3.11M  2.43MB/s    in 1.3s    \n",
            "\n",
            "2021-11-09 20:33:47 (2.43 MB/s) - ‘census-income.test.gz’ saved [3261416/3261416]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh1DqSO_aNDN"
      },
      "source": [
        "\n",
        "class MMoE(Layer):\n",
        "    \"\"\"\n",
        "    Multi-gate Mixture-of-Experts model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 units,\n",
        "                 num_experts,\n",
        "                 num_tasks,\n",
        "                 use_expert_bias=True,\n",
        "                 use_gate_bias=True,\n",
        "                 expert_activation='relu',\n",
        "                 gate_activation='softmax',\n",
        "                 expert_bias_initializer='zeros',\n",
        "                 gate_bias_initializer='zeros',\n",
        "                 expert_bias_regularizer=None,\n",
        "                 gate_bias_regularizer=None,\n",
        "                 expert_bias_constraint=None,\n",
        "                 gate_bias_constraint=None,\n",
        "                 expert_kernel_initializer='VarianceScaling',\n",
        "                 gate_kernel_initializer='VarianceScaling',\n",
        "                 expert_kernel_regularizer=None,\n",
        "                 gate_kernel_regularizer=None,\n",
        "                 expert_kernel_constraint=None,\n",
        "                 gate_kernel_constraint=None,\n",
        "                 activity_regularizer=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "         Method for instantiating MMoE layer.\n",
        "        :param units: Number of hidden units\n",
        "        :param num_experts: Number of experts\n",
        "        :param num_tasks: Number of tasks\n",
        "        :param use_expert_bias: Boolean to indicate the usage of bias in the expert weights\n",
        "        :param use_gate_bias: Boolean to indicate the usage of bias in the gate weights\n",
        "        :param expert_activation: Activation function of the expert weights\n",
        "        :param gate_activation: Activation function of the gate weights\n",
        "        :param expert_bias_initializer: Initializer for the expert bias\n",
        "        :param gate_bias_initializer: Initializer for the gate bias\n",
        "        :param expert_bias_regularizer: Regularizer for the expert bias\n",
        "        :param gate_bias_regularizer: Regularizer for the gate bias\n",
        "        :param expert_bias_constraint: Constraint for the expert bias\n",
        "        :param gate_bias_constraint: Constraint for the gate bias\n",
        "        :param expert_kernel_initializer: Initializer for the expert weights\n",
        "        :param gate_kernel_initializer: Initializer for the gate weights\n",
        "        :param expert_kernel_regularizer: Regularizer for the expert weights\n",
        "        :param gate_kernel_regularizer: Regularizer for the gate weights\n",
        "        :param expert_kernel_constraint: Constraint for the expert weights\n",
        "        :param gate_kernel_constraint: Constraint for the gate weights\n",
        "        :param activity_regularizer: Regularizer for the activity\n",
        "        :param kwargs: Additional keyword arguments for the Layer class\n",
        "        \"\"\"\n",
        "        # Hidden nodes parameter\n",
        "        self.units = units\n",
        "        self.num_experts = num_experts\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Weight parameter\n",
        "        self.expert_kernels = None\n",
        "        self.gate_kernels = None\n",
        "        self.expert_kernel_initializer = initializers.get(expert_kernel_initializer)\n",
        "        self.gate_kernel_initializer = initializers.get(gate_kernel_initializer)\n",
        "        self.expert_kernel_regularizer = regularizers.get(expert_kernel_regularizer)\n",
        "        self.gate_kernel_regularizer = regularizers.get(gate_kernel_regularizer)\n",
        "        self.expert_kernel_constraint = constraints.get(expert_kernel_constraint)\n",
        "        self.gate_kernel_constraint = constraints.get(gate_kernel_constraint)\n",
        "\n",
        "        # Activation parameter\n",
        "        self.expert_activation = activations.get(expert_activation)\n",
        "        self.gate_activation = activations.get(gate_activation)\n",
        "\n",
        "        # Bias parameter\n",
        "        self.expert_bias = None\n",
        "        self.gate_bias = None\n",
        "        self.use_expert_bias = use_expert_bias\n",
        "        self.use_gate_bias = use_gate_bias\n",
        "        self.expert_bias_initializer = initializers.get(expert_bias_initializer)\n",
        "        self.gate_bias_initializer = initializers.get(gate_bias_initializer)\n",
        "        self.expert_bias_regularizer = regularizers.get(expert_bias_regularizer)\n",
        "        self.gate_bias_regularizer = regularizers.get(gate_bias_regularizer)\n",
        "        self.expert_bias_constraint = constraints.get(expert_bias_constraint)\n",
        "        self.gate_bias_constraint = constraints.get(gate_bias_constraint)\n",
        "\n",
        "        # Activity parameter\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "        # Keras parameter\n",
        "        self.input_spec = InputSpec(min_ndim=2)\n",
        "        self.supports_masking = True\n",
        "\n",
        "        super(MMoE, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Method for creating the layer weights.\n",
        "        :param input_shape: Keras tensor (future input to layer)\n",
        "                            or list/tuple of Keras tensors to reference\n",
        "                            for weight shape computations\n",
        "        \"\"\"\n",
        "        assert input_shape is not None and len(input_shape) >= 2\n",
        "\n",
        "        input_dimension = input_shape[-1]\n",
        "\n",
        "        # Initialize expert weights (number of input features * number of units per expert * number of experts)\n",
        "        self.expert_kernels = self.add_weight(\n",
        "            name='expert_kernel',\n",
        "            shape=(input_dimension, self.units, self.num_experts),\n",
        "            initializer=self.expert_kernel_initializer,\n",
        "            regularizer=self.expert_kernel_regularizer,\n",
        "            constraint=self.expert_kernel_constraint,\n",
        "        )\n",
        "\n",
        "        # Initialize expert bias (number of units per expert * number of experts)\n",
        "        if self.use_expert_bias:\n",
        "            self.expert_bias = self.add_weight(\n",
        "                name='expert_bias',\n",
        "                shape=(self.units, self.num_experts),\n",
        "                initializer=self.expert_bias_initializer,\n",
        "                regularizer=self.expert_bias_regularizer,\n",
        "                constraint=self.expert_bias_constraint,\n",
        "            )\n",
        "\n",
        "        # Initialize gate weights (number of input features * number of experts * number of tasks)\n",
        "        self.gate_kernels = [self.add_weight(\n",
        "            name='gate_kernel_task_{}'.format(i),\n",
        "            shape=(input_dimension, self.num_experts),\n",
        "            initializer=self.gate_kernel_initializer,\n",
        "            regularizer=self.gate_kernel_regularizer,\n",
        "            constraint=self.gate_kernel_constraint\n",
        "        ) for i in range(self.num_tasks)]\n",
        "\n",
        "        # Initialize gate bias (number of experts * number of tasks)\n",
        "        if self.use_gate_bias:\n",
        "            self.gate_bias = [self.add_weight(\n",
        "                name='gate_bias_task_{}'.format(i),\n",
        "                shape=(self.num_experts,),\n",
        "                initializer=self.gate_bias_initializer,\n",
        "                regularizer=self.gate_bias_regularizer,\n",
        "                constraint=self.gate_bias_constraint\n",
        "            ) for i in range(self.num_tasks)]\n",
        "\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dimension})\n",
        "\n",
        "        super(MMoE, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        \"\"\"\n",
        "        Method for the forward function of the layer.\n",
        "        :param inputs: Input tensor\n",
        "        :param kwargs: Additional keyword arguments for the base method\n",
        "        :return: A tensor\n",
        "        \"\"\"\n",
        "        gate_outputs = []\n",
        "        final_outputs = []\n",
        "\n",
        "        # f_{i}(x) = activation(W_{i} * x + b), where activation is ReLU according to the paper\n",
        "        expert_outputs = tf.tensordot(a=inputs, b=self.expert_kernels, axes=1)\n",
        "        # Add the bias term to the expert weights if necessary\n",
        "        if self.use_expert_bias:\n",
        "            expert_outputs = K.bias_add(x=expert_outputs, bias=self.expert_bias)\n",
        "        expert_outputs = self.expert_activation(expert_outputs)\n",
        "\n",
        "        # g^{k}(x) = activation(W_{gk} * x + b), where activation is softmax according to the paper\n",
        "        for index, gate_kernel in enumerate(self.gate_kernels):\n",
        "            gate_output = K.dot(x=inputs, y=gate_kernel)\n",
        "            # Add the bias term to the gate weights if necessary\n",
        "            if self.use_gate_bias:\n",
        "                gate_output = K.bias_add(x=gate_output, bias=self.gate_bias[index])\n",
        "            gate_output = self.gate_activation(gate_output)\n",
        "            gate_outputs.append(gate_output)\n",
        "\n",
        "        # f^{k}(x) = sum_{i=1}^{n}(g^{k}(x)_{i} * f_{i}(x))\n",
        "        for gate_output in gate_outputs:\n",
        "            expanded_gate_output = K.expand_dims(gate_output, axis=1)\n",
        "            weighted_expert_output = expert_outputs * K.repeat_elements(expanded_gate_output, self.units, axis=1)\n",
        "            final_outputs.append(K.sum(weighted_expert_output, axis=2))\n",
        "\n",
        "        return final_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "        Method for computing the output shape of the MMoE layer.\n",
        "        :param input_shape: Shape tuple (tuple of integers)\n",
        "        :return: List of input shape tuple where the size of the list is equal to the number of tasks\n",
        "        \"\"\"\n",
        "        assert input_shape is not None and len(input_shape) >= 2\n",
        "\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[-1] = self.units\n",
        "        output_shape = tuple(output_shape)\n",
        "\n",
        "        return [output_shape for _ in range(self.num_tasks)]\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Method for returning the configuration of the MMoE layer.\n",
        "        :return: Config dictionary\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            'units': self.units,\n",
        "            'num_experts': self.num_experts,\n",
        "            'num_tasks': self.num_tasks,\n",
        "            'use_expert_bias': self.use_expert_bias,\n",
        "            'use_gate_bias': self.use_gate_bias,\n",
        "            'expert_activation': activations.serialize(self.expert_activation),\n",
        "            'gate_activation': activations.serialize(self.gate_activation),\n",
        "            'expert_bias_initializer': initializers.serialize(self.expert_bias_initializer),\n",
        "            'gate_bias_initializer': initializers.serialize(self.gate_bias_initializer),\n",
        "            'expert_bias_regularizer': regularizers.serialize(self.expert_bias_regularizer),\n",
        "            'gate_bias_regularizer': regularizers.serialize(self.gate_bias_regularizer),\n",
        "            'expert_bias_constraint': constraints.serialize(self.expert_bias_constraint),\n",
        "            'gate_bias_constraint': constraints.serialize(self.gate_bias_constraint),\n",
        "            'expert_kernel_initializer': initializers.serialize(self.expert_kernel_initializer),\n",
        "            'gate_kernel_initializer': initializers.serialize(self.gate_kernel_initializer),\n",
        "            'expert_kernel_regularizer': regularizers.serialize(self.expert_kernel_regularizer),\n",
        "            'gate_kernel_regularizer': regularizers.serialize(self.gate_kernel_regularizer),\n",
        "            'expert_kernel_constraint': constraints.serialize(self.expert_kernel_constraint),\n",
        "            'gate_kernel_constraint': constraints.serialize(self.gate_kernel_constraint),\n",
        "            'activity_regularizer': regularizers.serialize(self.activity_regularizer)\n",
        "        }\n",
        "        base_config = super(MMoE, self).get_config()\n",
        "\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9husAcAXaQ_g"
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# Fix numpy seed for reproducibility\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Fix random seed for reproducibility\n",
        "random.seed(SEED)\n",
        "\n",
        "# Fix TensorFlow graph-level seed for reproducibility\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEs35esLaV5t"
      },
      "source": [
        "# Simple callback to print out ROC-AUC\n",
        "class ROCCallback(Callback):\n",
        "    def __init__(self, training_data, validation_data, test_data):\n",
        "        self.train_X = training_data[0]\n",
        "        self.train_Y = training_data[1]\n",
        "        self.validation_X = validation_data[0]\n",
        "        self.validation_Y = validation_data[1]\n",
        "        self.test_X = test_data[0]\n",
        "        self.test_Y = test_data[1]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        train_prediction = self.model.predict(self.train_X)\n",
        "        validation_prediction = self.model.predict(self.validation_X)\n",
        "        test_prediction = self.model.predict(self.test_X)\n",
        "\n",
        "        # Iterate through each task and output their ROC-AUC across different datasets\n",
        "        for index, output_name in enumerate(self.model.output_names):\n",
        "            train_roc_auc = roc_auc_score(self.train_Y[index], train_prediction[index])\n",
        "            validation_roc_auc = roc_auc_score(self.validation_Y[index], validation_prediction[index])\n",
        "            test_roc_auc = roc_auc_score(self.test_Y[index], test_prediction[index])\n",
        "            print(\n",
        "                'ROC-AUC-{}-Train: {} ROC-AUC-{}-Validation: {} ROC-AUC-{}-Test: {}'.format(\n",
        "                    output_name, round(train_roc_auc, 4),\n",
        "                    output_name, round(validation_roc_auc, 4),\n",
        "                    output_name, round(test_roc_auc, 4)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qVivjY2abkr"
      },
      "source": [
        "def data_preparation():\n",
        "    # The column names are from\n",
        "    # https://www2.1010data.com/documentationcenter/prod/Tutorials/MachineLearningExamples/CensusIncomeDataSet.html\n",
        "    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n",
        "                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n",
        "                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n",
        "                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n",
        "                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
        "                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
        "                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n",
        "\n",
        "    # Load the dataset in Pandas\n",
        "    train_df = pd.read_csv(\n",
        "        '/content/census-income.data.gz',\n",
        "        delimiter=',',\n",
        "        header=None,\n",
        "        index_col=None,\n",
        "        names=column_names\n",
        "    )\n",
        "    other_df = pd.read_csv(\n",
        "        '/content/census-income.test.gz',\n",
        "        delimiter=',',\n",
        "        header=None,\n",
        "        index_col=None,\n",
        "        names=column_names\n",
        "    )\n",
        "\n",
        "    # First group of tasks according to the paper\n",
        "    label_columns = ['income_50k', 'marital_stat']\n",
        "\n",
        "    # One-hot encoding categorical columns\n",
        "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
        "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
        "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
        "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
        "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
        "                           'vet_question']\n",
        "    train_raw_labels = train_df[label_columns]\n",
        "    other_raw_labels = other_df[label_columns]\n",
        "    transformed_train = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
        "    transformed_other = pd.get_dummies(other_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
        "\n",
        "    # Filling the missing column in the other set\n",
        "    transformed_other['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n",
        "\n",
        "    # One-hot encoding categorical labels\n",
        "    train_income = to_categorical((train_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
        "    train_marital = to_categorical((train_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
        "    other_income = to_categorical((other_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
        "    other_marital = to_categorical((other_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
        "\n",
        "    dict_outputs = {\n",
        "        'income': train_income.shape[1],\n",
        "        'marital': train_marital.shape[1]\n",
        "    }\n",
        "    dict_train_labels = {\n",
        "        'income': train_income,\n",
        "        'marital': train_marital\n",
        "    }\n",
        "    dict_other_labels = {\n",
        "        'income': other_income,\n",
        "        'marital': other_marital\n",
        "    }\n",
        "    output_info = [(dict_outputs[key], key) for key in sorted(dict_outputs.keys())]\n",
        "\n",
        "    # Split the other dataset into 1:1 validation to test according to the paper\n",
        "    validation_indices = transformed_other.sample(frac=0.5, replace=False, random_state=SEED).index\n",
        "    test_indices = list(set(transformed_other.index) - set(validation_indices))\n",
        "    validation_data = transformed_other.iloc[validation_indices]\n",
        "    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n",
        "    test_data = transformed_other.iloc[test_indices]\n",
        "    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n",
        "    train_data = transformed_train\n",
        "    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n",
        "\n",
        "    return train_data, train_label, validation_data, validation_label, test_data, test_label, output_info\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRtU-5gGagS1"
      },
      "source": [
        "def main():\n",
        "    # Load the data\n",
        "    train_data, train_label, validation_data, validation_label, test_data, test_label, output_info = data_preparation()\n",
        "    num_features = train_data.shape[1]\n",
        "\n",
        "    print('Training data shape = {}'.format(train_data.shape))\n",
        "    print('Validation data shape = {}'.format(validation_data.shape))\n",
        "    print('Test data shape = {}'.format(test_data.shape))\n",
        "\n",
        "    # Set up the input layer\n",
        "    input_layer = Input(shape=(num_features,))\n",
        "\n",
        "    # Set up MMoE layer\n",
        "    mmoe_layers = MMoE(\n",
        "        units=4,\n",
        "        num_experts=8,\n",
        "        num_tasks=2\n",
        "    )(input_layer)\n",
        "\n",
        "    output_layers = []\n",
        "\n",
        "    # Build tower layer from MMoE layer\n",
        "    for index, task_layer in enumerate(mmoe_layers):\n",
        "        tower_layer = Dense(\n",
        "            units=8,\n",
        "            activation='relu',\n",
        "            kernel_initializer=VarianceScaling())(task_layer)\n",
        "        output_layer = Dense(\n",
        "            units=output_info[index][0],\n",
        "            name=output_info[index][1],\n",
        "            activation='softmax',\n",
        "            kernel_initializer=VarianceScaling())(tower_layer)\n",
        "        output_layers.append(output_layer)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=[input_layer], outputs=output_layers)\n",
        "    adam_optimizer = Adam()\n",
        "    model.compile(\n",
        "        loss={'income': 'binary_crossentropy', 'marital': 'binary_crossentropy'},\n",
        "        optimizer=adam_optimizer,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Print out model architecture summary\n",
        "    model.summary()\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x=train_data,\n",
        "        y=train_label,\n",
        "        validation_data=(validation_data, validation_label),\n",
        "        callbacks=[\n",
        "            ROCCallback(\n",
        "                training_data=(train_data, train_label),\n",
        "                validation_data=(validation_data, validation_label),\n",
        "                test_data=(test_data, test_label)\n",
        "            )\n",
        "        ],\n",
        "        epochs=10\n",
        "    )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDPj5GW2ajbH",
        "outputId": "9b2c5c3b-446f-4c6b-8a20-946664401b5d"
      },
      "source": [
        "main()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape = (199523, 499)\n",
            "Validation data shape = (49881, 499)\n",
            "Test data shape = (49881, 499)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 499)]        0           []                               \n",
            "                                                                                                  \n",
            " m_mo_e (MMoE)                  [(None, 4),          24000       ['input_1[0][0]']                \n",
            "                                 (None, 4)]                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 8)            40          ['m_mo_e[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 8)            40          ['m_mo_e[0][1]']                 \n",
            "                                                                                                  \n",
            " income (Dense)                 (None, 2)            18          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " marital (Dense)                (None, 2)            18          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,116\n",
            "Trainable params: 24,116\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "6228/6236 [============================>.] - ETA: 0s - loss: 0.4773 - income_loss: 0.1836 - marital_loss: 0.2937 - income_accuracy: 0.9378 - marital_accuracy: 0.8887ROC-AUC-income-Train: 0.9139 ROC-AUC-income-Validation: 0.9147 ROC-AUC-income-Test: 0.9137\n",
            "ROC-AUC-marital-Train: 0.968 ROC-AUC-marital-Validation: 0.958 ROC-AUC-marital-Test: 0.9595\n",
            "6236/6236 [==============================] - 36s 6ms/step - loss: 0.4771 - income_loss: 0.1835 - marital_loss: 0.2936 - income_accuracy: 0.9378 - marital_accuracy: 0.8888 - val_loss: 0.3661 - val_income_loss: 0.1647 - val_marital_loss: 0.2014 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9313\n",
            "Epoch 2/10\n",
            "6232/6236 [============================>.] - ETA: 0s - loss: 0.3257 - income_loss: 0.1532 - marital_loss: 0.1725 - income_accuracy: 0.9380 - marital_accuracy: 0.9391ROC-AUC-income-Train: 0.917 ROC-AUC-income-Validation: 0.9146 ROC-AUC-income-Test: 0.9145\n",
            "ROC-AUC-marital-Train: 0.9746 ROC-AUC-marital-Validation: 0.9614 ROC-AUC-marital-Test: 0.9619\n",
            "6236/6236 [==============================] - 37s 6ms/step - loss: 0.3257 - income_loss: 0.1532 - marital_loss: 0.1725 - income_accuracy: 0.9379 - marital_accuracy: 0.9391 - val_loss: 0.3671 - val_income_loss: 0.1515 - val_marital_loss: 0.2157 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9231\n",
            "Epoch 3/10\n",
            "6222/6236 [============================>.] - ETA: 0s - loss: 0.2958 - income_loss: 0.1511 - marital_loss: 0.1446 - income_accuracy: 0.9379 - marital_accuracy: 0.9467ROC-AUC-income-Train: 0.9183 ROC-AUC-income-Validation: 0.9152 ROC-AUC-income-Test: 0.9149\n",
            "ROC-AUC-marital-Train: 0.979 ROC-AUC-marital-Validation: 0.9658 ROC-AUC-marital-Test: 0.9652\n",
            "6236/6236 [==============================] - 33s 5ms/step - loss: 0.2957 - income_loss: 0.1511 - marital_loss: 0.1446 - income_accuracy: 0.9379 - marital_accuracy: 0.9467 - val_loss: 0.3668 - val_income_loss: 0.1644 - val_marital_loss: 0.2023 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9258\n",
            "Epoch 4/10\n",
            "6226/6236 [============================>.] - ETA: 0s - loss: 0.2860 - income_loss: 0.1458 - marital_loss: 0.1402 - income_accuracy: 0.9380 - marital_accuracy: 0.9479ROC-AUC-income-Train: 0.9199 ROC-AUC-income-Validation: 0.9182 ROC-AUC-income-Test: 0.9185\n",
            "ROC-AUC-marital-Train: 0.9841 ROC-AUC-marital-Validation: 0.9699 ROC-AUC-marital-Test: 0.9699\n",
            "6236/6236 [==============================] - 36s 6ms/step - loss: 0.2862 - income_loss: 0.1459 - marital_loss: 0.1403 - income_accuracy: 0.9379 - marital_accuracy: 0.9479 - val_loss: 0.3860 - val_income_loss: 0.1490 - val_marital_loss: 0.2371 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9094\n",
            "Epoch 5/10\n",
            "6236/6236 [==============================] - ETA: 0s - loss: 0.2816 - income_loss: 0.1456 - marital_loss: 0.1360 - income_accuracy: 0.9379 - marital_accuracy: 0.9493ROC-AUC-income-Train: 0.9235 ROC-AUC-income-Validation: 0.9194 ROC-AUC-income-Test: 0.9184\n",
            "ROC-AUC-marital-Train: 0.982 ROC-AUC-marital-Validation: 0.9674 ROC-AUC-marital-Test: 0.9672\n",
            "6236/6236 [==============================] - 33s 5ms/step - loss: 0.2816 - income_loss: 0.1456 - marital_loss: 0.1360 - income_accuracy: 0.9379 - marital_accuracy: 0.9493 - val_loss: 0.3918 - val_income_loss: 0.1683 - val_marital_loss: 0.2235 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9158\n",
            "Epoch 6/10\n",
            "6236/6236 [==============================] - ETA: 0s - loss: 0.2771 - income_loss: 0.1432 - marital_loss: 0.1339 - income_accuracy: 0.9379 - marital_accuracy: 0.9498ROC-AUC-income-Train: 0.926 ROC-AUC-income-Validation: 0.9215 ROC-AUC-income-Test: 0.9215\n",
            "ROC-AUC-marital-Train: 0.9829 ROC-AUC-marital-Validation: 0.9648 ROC-AUC-marital-Test: 0.9646\n",
            "6236/6236 [==============================] - 37s 6ms/step - loss: 0.2771 - income_loss: 0.1432 - marital_loss: 0.1339 - income_accuracy: 0.9379 - marital_accuracy: 0.9498 - val_loss: 0.4545 - val_income_loss: 0.1725 - val_marital_loss: 0.2820 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9056\n",
            "Epoch 7/10\n",
            "6236/6236 [==============================] - ETA: 0s - loss: 0.2768 - income_loss: 0.1418 - marital_loss: 0.1350 - income_accuracy: 0.9379 - marital_accuracy: 0.9503ROC-AUC-income-Train: 0.9266 ROC-AUC-income-Validation: 0.9237 ROC-AUC-income-Test: 0.923\n",
            "ROC-AUC-marital-Train: 0.9859 ROC-AUC-marital-Validation: 0.9696 ROC-AUC-marital-Test: 0.9691\n",
            "6236/6236 [==============================] - 39s 6ms/step - loss: 0.2768 - income_loss: 0.1418 - marital_loss: 0.1350 - income_accuracy: 0.9379 - marital_accuracy: 0.9503 - val_loss: 0.3990 - val_income_loss: 0.1673 - val_marital_loss: 0.2317 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9107\n",
            "Epoch 8/10\n",
            "6231/6236 [============================>.] - ETA: 0s - loss: 0.2707 - income_loss: 0.1421 - marital_loss: 0.1285 - income_accuracy: 0.9379 - marital_accuracy: 0.9511ROC-AUC-income-Train: 0.9369 ROC-AUC-income-Validation: 0.9342 ROC-AUC-income-Test: 0.9333\n",
            "ROC-AUC-marital-Train: 0.9839 ROC-AUC-marital-Validation: 0.964 ROC-AUC-marital-Test: 0.9636\n",
            "6236/6236 [==============================] - 38s 6ms/step - loss: 0.2706 - income_loss: 0.1421 - marital_loss: 0.1285 - income_accuracy: 0.9379 - marital_accuracy: 0.9511 - val_loss: 0.4183 - val_income_loss: 0.1769 - val_marital_loss: 0.2414 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9090\n",
            "Epoch 9/10\n",
            "6230/6236 [============================>.] - ETA: 0s - loss: 0.2658 - income_loss: 0.1410 - marital_loss: 0.1249 - income_accuracy: 0.9379 - marital_accuracy: 0.9522ROC-AUC-income-Train: 0.9292 ROC-AUC-income-Validation: 0.9254 ROC-AUC-income-Test: 0.9245\n",
            "ROC-AUC-marital-Train: 0.9868 ROC-AUC-marital-Validation: 0.968 ROC-AUC-marital-Test: 0.9676\n",
            "6236/6236 [==============================] - 35s 6ms/step - loss: 0.2658 - income_loss: 0.1410 - marital_loss: 0.1248 - income_accuracy: 0.9379 - marital_accuracy: 0.9522 - val_loss: 0.4420 - val_income_loss: 0.1590 - val_marital_loss: 0.2830 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.8935\n",
            "Epoch 10/10\n",
            "6229/6236 [============================>.] - ETA: 0s - loss: 0.2663 - income_loss: 0.1399 - marital_loss: 0.1265 - income_accuracy: 0.9381 - marital_accuracy: 0.9518ROC-AUC-income-Train: 0.927 ROC-AUC-income-Validation: 0.9238 ROC-AUC-income-Test: 0.9218\n",
            "ROC-AUC-marital-Train: 0.9839 ROC-AUC-marital-Validation: 0.9661 ROC-AUC-marital-Test: 0.9659\n",
            "6236/6236 [==============================] - 34s 5ms/step - loss: 0.2663 - income_loss: 0.1399 - marital_loss: 0.1264 - income_accuracy: 0.9381 - marital_accuracy: 0.9519 - val_loss: 0.4029 - val_income_loss: 0.1658 - val_marital_loss: 0.2370 - val_income_accuracy: 0.9378 - val_marital_accuracy: 0.9114\n"
          ]
        }
      ]
    }
  ]
}